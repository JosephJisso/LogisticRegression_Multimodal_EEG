# -*- coding: utf-8 -*-
"""EEG MODEL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B0-8F4OUzcSVCUPzP28lK351njjr9VX2
"""

!pip install kaggle

import os

# Create the .kaggle directory if it doesn't exist
!mkdir -p ~/.kaggle

# Move the kaggle.json file to the .kaggle directory
!mv kaggle.json ~/.kaggle/

# Set permissions for the kaggle.json file
!chmod 600 ~/.kaggle/kaggle.json

# Verify that the file exists and permissions are set correctly
!ls -la ~/.kaggle/

print("kaggle.json has been moved and permissions set.")

import os

# Create the .kaggle directory if it doesn't exist
!mkdir -p ~/.kaggle

# Move the kaggle.json file to the .kaggle directory
!mv kaggle.json ~/.kaggle/

# Set permissions for the kaggle.json file
!chmod 600 ~/.kaggle/kaggle.json

# Verify that the file exists and permissions are set correctly
!ls -la ~/.kaggle/

print("kaggle.json has been moved and permissions set.")

import os

# Create the .kaggle directory if it doesn't exist
!mkdir -p ~/.kaggle

# Move the kaggle.json file to the .kaggle directory
!mv kaggle.json ~/.kaggle/

# Set permissions for the kaggle.json file
!chmod 600 ~/.kaggle/kaggle.json

# Verify that the file exists and permissions are set correctly
!ls -la ~/.kaggle/

print("kaggle.json has been moved and permissions set.")

from google.colab import files

print("Please upload your kaggle.json file. Click 'Choose Files' below.")
uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))
  if fn == 'kaggle.json':
    print("kaggle.json uploaded successfully.")
  else:
    print("Warning: Expected 'kaggle.json' but received '{}'. Please upload the correct file.".format(fn))

import os

# Create the .kaggle directory if it doesn't exist
!mkdir -p ~/.kaggle

# Move the kaggle.json file to the .kaggle directory
!mv kaggle.json ~/.kaggle/

# Set permissions for the kaggle.json file
!chmod 600 ~/.kaggle/kaggle.json

# Verify that the file exists and permissions are set correctly
!ls -la ~/.kaggle/

print("kaggle.json has been moved and permissions set.")

!pwd

!ls

!ls deap-dataset

!kaggle datasets download -d manh123df/deap-dataset

!unzip deap-dataset.zip
print("Dataset unzipped successfully.")

import os
import numpy as np
import pandas as pd
import pickle  # Import the pickle module

from scipy.io import loadmat
from scipy.signal import butter, filtfilt, welch

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score, precision_score,
    recall_score, f1_score,
    confusion_matrix, classification_report
)

# -----------------------------
# EEG preprocessing
# -----------------------------
def bandpass_filter(signal, fs=128, low=0.5, high=45, order=4):
    nyq = 0.5 * fs
    b, a = butter(order, [low/nyq, high/nyq], btype='band')
    return filtfilt(b, a, signal)

def extract_features(signal, fs=128):
    feats = {
        "mean": np.mean(signal),
        "var": np.var(signal)
    }

    freqs, psd = welch(signal, fs)

    def bandpower(l, h):
        return np.mean(psd[(freqs >= l) & (freqs <= h)])

    feats["delta"] = bandpower(0.5, 4)
    feats["theta"] = bandpower(4, 8)
    feats["alpha"] = bandpower(8, 13)
    feats["beta"]  = bandpower(13, 30)

    return feats

# -----------------------------
# DATA PATH (MATLAB VERSION)
# -----------------------------
DATA_DIR = "deap-dataset/data_preprocessed_python"

X_all, y_all = [], []

for file in os.listdir(DATA_DIR):
    if file.endswith(".dat"):
        # Use pickle.load instead of loadmat for .dat files
        with open(os.path.join(DATA_DIR, file), 'rb') as f:
            mat = pickle.load(f, encoding='latin1') # 'latin1' is often needed for older pickled Python 2 objects

        eeg_data = mat["data"]     # (40 trials × 32 channels × time)
        labels = mat["labels"]     # (40 × 4)

        for i in range(eeg_data.shape[0]):
            trial_feats = {}
            for ch in range(eeg_data.shape[1]):
                sig = bandpass_filter(eeg_data[i, ch])
                feats = extract_features(sig)
                for k, v in feats.items():
                    trial_feats[f"ch{ch}_{k}"] = v

            # Depression proxy
            valence = labels[i, 0]
            y = 1 if valence <= 4 else 0

            X_all.append(trial_feats)
            y_all.append(y)

# -----------------------------
# ML PIPELINE
# -----------------------------
X = pd.DataFrame(X_all)
y = pd.Series(y_all)

print("Feature shape:", X.shape)
print("Label distribution:\n", y.value_counts())

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, stratify=y, random_state=42
)

model = LogisticRegression(max_iter=5000, class_weight="balanced")
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("\nAccuracy :", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall   :", recall_score(y_test, y_pred))
print("F1-score :", f1_score(y_test, y_pred))